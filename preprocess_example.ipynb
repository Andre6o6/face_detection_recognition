{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import json\n",
    "\n",
    "import numpy as np\n",
    "import dlib\n",
    "import cv2\n",
    "from skimage import io\n",
    "\n",
    "from utils import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_folder = './faces/mine/s01/'\n",
    "\n",
    "IMAGE_FORMATS = {'.jpg', '.jpeg', '.png'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test opencv vs dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not detected on 5 images\n",
      "['./faces/mine/s01/04.jpg', './faces/mine/s01/05.jpg', './faces/mine/s01/08.jpg', './faces/mine/s01/12.jpeg', './faces/mine/s01/18.jpeg']\n"
     ]
    }
   ],
   "source": [
    "from skimage.draw import polygon_perimeter\n",
    "\n",
    "def test_dlib():\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "    #fig=plt.figure()\n",
    "    no_faces = []\n",
    "    for name in get_images(img_folder):\n",
    "        image = io.imread(img_folder + name)\n",
    "        image = image[:,:,:3]     #discard alpha channel\n",
    "\n",
    "        face_rects = list(detector(image, 1))\n",
    "        if face_rects==[]:\n",
    "            no_faces.append(img_folder + name)\n",
    "            continue\n",
    "\n",
    "        face_rect = face_rects[0]\n",
    "\n",
    "        d = face_rect\n",
    "        rr,cc = polygon_perimeter([d.top(), d.top(), d.bottom(), d.bottom()],\n",
    "                                 [d.right(), d.left(), d.left(), d.right()])\n",
    "\n",
    "        img_with_rect = image.copy()\n",
    "        width = 3\n",
    "        for i in range(-width, width):\n",
    "            img_with_rect[rr + i, cc + i] = (255, 0, 0)\n",
    "\n",
    "\n",
    "        #plt.imshow(img_with_rect)\n",
    "        #plt.show()\n",
    "        plt.imsave('./temp/testdlib/'+name, img_with_rect)\n",
    "\n",
    "    print( 'Not detected on {} images'.format(len(no_faces)) )\n",
    "    return no_faces\n",
    "    \n",
    "def test_cv():\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "    no_faces = []\n",
    "    for name in get_images(img_folder):    \n",
    "        image = io.imread(img_folder + name)\n",
    "        image = image[:,:,:3]     #discard alpha channel\n",
    "\n",
    "        faces = face_cascade.detectMultiScale(image)\n",
    "\n",
    "        if faces==():\n",
    "            no_faces.append(img_folder + name)\n",
    "            continue\n",
    "\n",
    "        (x,y,w,h) = faces[0]\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "        plt.imsave('./temp/testcv2/'+name, image)\n",
    "\n",
    "    print( 'Not detected on {} images'.format(len(no_faces)) )\n",
    "    return no_faces\n",
    "\n",
    "#test_dlib()\n",
    "#test_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(path):\n",
    "    return list(filter(lambda s: os.path.isfile(os.path.join(path, s)) and \n",
    "                       os.path.splitext(s)[1] in IMAGE_FORMATS, os.listdir(path)))\n",
    "\n",
    "\n",
    "def get_folders(path):\n",
    "    return list(filter(lambda s: os.path.isdir(os.path.join(path, s)), os.listdir(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entry = ['subject', 'name', 'path'])\n",
    "def grab_db_plain(path, divisor):\n",
    "    res = []\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        file_path = os.path.join(path, file)\n",
    "        ext = os.path.splitext(file)[1]\n",
    "        if os.path.isfile(file_path) and ext in IMAGE_FORMATS:\n",
    "            subject, name = file.split(divisor)\n",
    "            res.append((path + subject, name, file_path))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def grab_db_folders(path):\n",
    "    res = []\n",
    "\n",
    "    for dir in os.listdir(path):\n",
    "        dir_path = os.path.join(path, dir)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for file in os.listdir(dir_path):\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                ext = os.path.splitext(file)[1]\n",
    "                if os.path.isfile(file_path) and ext in IMAGE_FORMATS:\n",
    "                    res.append((path + dir, file, file_path))\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_entry_subjects(entries):\n",
    "    subjects = []\n",
    "    for k in entries.keys():\n",
    "        subjects.extend(list(set(map(lambda e: e[0], entries[k]))))\n",
    "    return subjects\n",
    "\n",
    "def train_test_split_subjects(entries, test_ratio=0.2):\n",
    "    '''\n",
    "    Split subjects into train and dev sets\n",
    "    '''\n",
    "    subjects = get_entry_subjects(entries)\n",
    "    n_subjects = len(subjects)\n",
    "    n_test_subjects = max(1, math.ceil(n_subjects * test_ratio))\n",
    "    random.shuffle(subjects)\n",
    "\n",
    "    return subjects[:n_test_subjects], subjects[n_test_subjects:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating ./faces/fei/labels/\n",
      "Creating ./faces/caltech_faces/labels/\n",
      "Creating ./faces/mine/labels/\n"
     ]
    }
   ],
   "source": [
    "#Create directories for label data\n",
    "for dir in ['fei/','caltech_faces/','gt_db/','mine/']:\n",
    "    path = base_dir + dir + 'labels/'\n",
    "    if not os.path.exists(path):\n",
    "        print('Creating {}'.format(path))\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './faces/'\n",
    "entries = {\n",
    "    #'fei': grab_db_plain(base_dir + 'fei/', '-'),\n",
    "    #'caltech_faces': grab_db_folders(base_dir + 'caltech_faces/'),\n",
    "    #'gt_db': grab_db_folders(base_dir + 'gt_db/'),\n",
    "    'mine': grab_db_folders(base_dir + 'mine/')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not detected on 9 images\n"
     ]
    }
   ],
   "source": [
    "#Process photos\n",
    "def label_bboxes_on_images(dirs=['fei', 'caltech_faces', 'gt_db', 'mine']):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    no_faces = []\n",
    "\n",
    "    for dir in dirs:\n",
    "        label_path = base_dir + dir + '/labels/'\n",
    "        metadata = []\n",
    "\n",
    "        for (subject, photo, filename) in entries[dir]:\n",
    "            img = io.imread(filename)\n",
    "            img = img[:,:,:3]    #remove alpha channel\n",
    "\n",
    "            faces = list(detector(img, 1))\n",
    "\n",
    "            if len(faces) == 0:\n",
    "                no_faces.append(filename)\n",
    "                continue\n",
    "\n",
    "            face = faces[0]\n",
    "            rect_meta = {'top':face.top(), 'bottom':face.bottom(), \n",
    "                         'right':face.right(), 'left':face.left()}\n",
    "            full_meta = {'path':filename, \n",
    "                         'subjects':[ {'subject':subject, 'rect':rect_meta} ] }\n",
    "\n",
    "            metadata.append(full_meta)\n",
    "\n",
    "        with open(label_path + 'labels.txt', 'w+') as fs:\n",
    "            json.dump(metadata, fs)\n",
    "\n",
    "    print(\"Not detected on {} images\".format(len(no_faces)))\n",
    "\n",
    "    return no_faces\n",
    "\n",
    "#no_faces = label_bboxes_on_images()\n",
    "#with open('./faces/not_detected2.txt', 'w') as fs:\n",
    "#    json.dump(no_faces, fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_count = 0\n",
    "for k in entries.keys():\n",
    "    subject_count += len(list(set(map(lambda e: e[0], entries[k]))))\n",
    "\n",
    "subject_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "photo_num = 30\n",
    "\n",
    "#Load meta\n",
    "with open('faces/mine/labels/labels.txt', 'r') as f:\n",
    "    a = json.load(f)\n",
    "subj = a[photo_num]['subjects'][0]\n",
    "rect = subj['rect']\n",
    "top, bottom, left, right = rect['top'], rect['bottom'], rect['left'], rect['right']\n",
    "\n",
    "#Load image\n",
    "img = Image.open(a[photo_num]['path'])\n",
    "\n",
    "#Crop\n",
    "d = min(img.height, img.width)\n",
    "scale = 704/d\n",
    "img = img.resize((int(img.width*scale), int(img.height*scale)))\n",
    "(top, bottom, left, right) = Resize((top, bottom, left, right), (scale,scale))\n",
    "\n",
    "crop_rect = CleverRandomCropArea((top, bottom, left, right), img.size, crop_size=(704,704))\n",
    "img = img.crop(crop_rect)\n",
    "(top, bottom, left, right) = Crop((top, bottom, left, right), crop_rect)\n",
    "\n",
    "# Draw grid\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "cells = np.linspace(0, 1, 11 + 1)\n",
    "\n",
    "for x in cells:\n",
    "    line = ((x*704, 0), (x*704, img.height))\n",
    "    draw.line(line, fill=128)\n",
    "    \n",
    "for y in cells:\n",
    "    line = ((0, y*704), (img.width, y*704))\n",
    "    draw.line(line, fill=128)\n",
    "\n",
    "#Draw bbox\n",
    "draw.rectangle((left, top,right, bottom))\n",
    "\n",
    "del draw\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell index: (3, 4)\n",
      "Bbox center offset: (0.49, 0.68)\n",
      "Bbox size: (291.00, 291.00) vs actual size: (291, 291)\n"
     ]
    }
   ],
   "source": [
    "#Testing, testing, 1, 2, 3...\n",
    "n_classes = subject_count\n",
    "feature_map_size = (11,11)\n",
    "subj_index = 0\n",
    "\n",
    "feature_map = np.zeros((4+1+n_classes, feature_map_size[0], feature_map_size[1]), dtype=np.float32)\n",
    "\n",
    "center_x = (left+right)/2/img.width\n",
    "center_y = (top+bottom)/2/img.height\n",
    "\n",
    "\n",
    "cells = np.linspace(0, 1, 11 + 1)\n",
    "cell_index_x = np.argmax(cells > center_x)-1\n",
    "offset_x = (center_x - cells[cell_index_x])/(cells[cell_index_x + 1] - cells[cell_index_x])\n",
    "\n",
    "cells = np.linspace(0, 1, 11 + 1)\n",
    "cell_index_y = np.argmax(cells > center_y)-1\n",
    "offset_y = (center_y - cells[cell_index_y])/(cells[cell_index_y + 1] - cells[cell_index_y])\n",
    "\n",
    "anchor = (1,1)  #TODO: another anchors\n",
    "            \n",
    "bbox_height = abs(top - bottom)\n",
    "bbox_width = abs(right - left)\n",
    "\n",
    "t_w = np.log(bbox_width/anchor[0])\n",
    "t_h = np.log(bbox_height/anchor[1])\n",
    "\n",
    "#Put everything into feature feature_map\n",
    "feature_map[:5, cell_index_x, cell_index_y] = offset_x, offset_y, t_w, t_h, 1\n",
    "feature_map[5 + subj_index, cell_index_x, cell_index_y] = 1\n",
    "\n",
    "print(\"Cell index:\", (cell_index_x, cell_index_y))\n",
    "print(\"Bbox center offset: ({:.2f}, {:.2f})\".format(offset_x,offset_y))\n",
    "print(\"Bbox size: ({:.2f}, {:.2f}) vs actual size: ({}, {})\".format(np.exp(t_w), np.exp(t_h), abs(top-bottom), abs(left-right)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "s = 704\n",
    "\n",
    "#Draw cell\n",
    "draw.rectangle((cells[cell_index_x]*s, cells[cell_index_y]*s, \n",
    "               cells[cell_index_x+1]*s, cells[cell_index_y+1]*s), \n",
    "               outline=\"black\")\n",
    "\n",
    "#Draw actual center\n",
    "draw.ellipse((center_x*s-5, center_y*s-5, center_x*s+5, center_y*s+5), fill=\"red\")\n",
    "\n",
    "#Draw offset within a cell\n",
    "cell_size = cells[cell_index_x+1]*s - cells[cell_index_x]*s\n",
    "draw.ellipse((cells[cell_index_x]*s + offset_x*cell_size - 3, \n",
    "              cells[cell_index_y]*s + offset_y*cell_size - 3, \n",
    "              cells[cell_index_x]*s + offset_x*cell_size + 3, \n",
    "              cells[cell_index_y]*s + offset_y*cell_size + 3), fill=\"black\")\n",
    "del draw\n",
    "\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 704, 704])\n",
      "torch.Size([1, 64, 352, 352])\n",
      "torch.Size([1, 64, 176, 176])\n",
      "torch.Size([1, 64, 176, 176])\n",
      "torch.Size([1, 128, 88, 88])\n",
      "torch.Size([1, 256, 44, 44])\n",
      "torch.Size([1, 512, 22, 22])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.models import resnet34\n",
    "\n",
    "img = Image.open(a[0]['path'])\n",
    "img = img.resize((704,704))\n",
    "\n",
    "x = transforms.ToTensor()(img)\n",
    "x = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])(x).unsqueeze(0)\n",
    "\n",
    "encoder = resnet34(pretrained=True)\n",
    "\n",
    "print(x.shape)\n",
    "x = encoder.conv1(x)\n",
    "print(x.shape)\n",
    "x = encoder.bn1(x)\n",
    "x = encoder.relu(x)\n",
    "x = encoder.maxpool(x)\n",
    "print(x.shape)\n",
    "x = encoder.layer1(x)\n",
    "print(x.shape)\n",
    "x = encoder.layer2(x)\n",
    "print(x.shape)\n",
    "x = encoder.layer3(x)\n",
    "print(x.shape)\n",
    "x = encoder.layer4(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename images\n",
    "path = './faces/mine/'\n",
    "for dir in os.listdir(path):\n",
    "    dir_path = os.path.join(path, dir)\n",
    "    if os.path.isdir(dir_path):\n",
    "        for i, file in enumerate(os.listdir(dir_path)):\n",
    "            file_path = os.path.join(dir_path, file)\n",
    "            ext = os.path.splitext(file)[1]\n",
    "            if os.path.isfile(file_path) and ext in IMAGE_FORMATS:\n",
    "                os.rename(file_path, os.path.join(dir_path, str(i)+ext))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
